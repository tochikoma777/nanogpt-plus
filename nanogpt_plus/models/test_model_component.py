#å®Œæˆæ£€æŸ¥æ¸…å•

from nanogpt_plus.models import GPT, create_model, LayerNorm, CausalSelfAttention, Block
from nanogpt_plus.config import ModelConfig
import torch

print("=== æ£€æŸ¥æ¨¡å‹æ–‡ä»¶ ===")
# åˆ›å»ºé…ç½®
cfg = ModelConfig(n_layer=2, n_embd=128, n_head=4, block_size=64, vocab_size=1000)

# æµ‹è¯•å„ç»„ä»¶
print('æµ‹è¯•LayerNorm...')
ln = LayerNorm(128, bias=True)
x = torch.randn(2, 10, 128)
y = ln(x)
assert y.shape == x.shape
print('âœ“ LayerNormæ­£å¸¸')

print('æµ‹è¯•CausalSelfAttention...')
attn = CausalSelfAttention(cfg)
x = torch.randn(2, 10, 128)
y = attn(x)
assert y.shape == x.shape
print('âœ“ Attentionæ­£å¸¸')

print('æµ‹è¯•Block...')
block = Block(cfg)
y = block(x)
assert y.shape == x.shape
print('âœ“ Blockæ­£å¸¸')

print('æµ‹è¯•å®Œæ•´GPT...')
model = create_model(cfg)
logits, _ = model(torch.randint(0, 1000, (2, 10)))
assert logits.shape == (2, 10, 1000)
print('âœ“ GPTæ¨¡å‹æ­£å¸¸')
print('\nğŸ‰ æ‰€æœ‰ç»„ä»¶æµ‹è¯•é€šè¿‡ï¼')

print("\n=== æ˜¾ç¤ºæ¨¡å‹ç»“æ„ ===")
from nanogpt_plus.models import create_model
from nanogpt_plus.config import ModelConfig

cfg = ModelConfig()
model = create_model(cfg)
print(f'æ¨¡å‹: {cfg.name}')
print(f'æ€»å‚æ•°é‡: {model.get_num_params()/1e6:.1f}M')
print(f'å±‚æ•°: {cfg.n_layer}')
print(f'æ³¨æ„åŠ›å¤´æ•°: {cfg.n_head}')
print(f'åµŒå…¥ç»´åº¦: {cfg.n_embd}')